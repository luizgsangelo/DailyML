{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb5bddd3-6a5d-4066-a5b8-bc291b7151a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Importando Bibliotecas e primeiras modificações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa93b6c0-0134-499c-a518-637acf6d6def",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Adicionando escalonamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "624ba537-2d67-4981-96a8-14e0d3f0484d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2eb0f54-2f96-4bb7-aee1-c2448c8ec655",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22e6edd1-1644-4eed-b12e-d974bfab33ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3bea3a2-4383-4e74-8ee2-8e54a416b36b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import databricks.connect as db_connect\n",
    "import mlflow.tracking._model_registry.utils\n",
    "\n",
    "# Workaround to set the registry URI manually\n",
    "mlflow.tracking._model_registry.utils._get_registry_uri_from_spark_session = lambda: \"databricks-uc\"\n",
    "\n",
    "mlflow.login() # This prints an INFO-log: Login successful!\n",
    "# mlflow.set_model_uri(\"databricks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5696d52c-7095-44a8-bb08-0e49f8aba899",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from typing import Optional\n",
    "from sklearn.impute import KNNImputer\n",
    "import seaborn as sns \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d07b5d1-9d3c-4147-a456-29b62610aafc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    df = spark.read.table(\"workspace.ml_datasets.house_prediction_train\")\n",
    "    train = df.toPandas()\n",
    "    X = train.drop(columns=[\"SalePrice\",\"Id\"])\n",
    "    y = train[\"SalePrice\"]\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,train_size=0.8,random_state=42)\n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "X_train,X_test,y_train,y_test = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d320e61f-6d50-4be5-b1c9-053d4f16e4f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Traduzindo dados categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "413636d1-9508-4557-a27e-73a7d3921ce9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Mapping utilizado com base em reposta de IA para tornar os nomes mais descritivos:\n",
    "value_mapping = {\n",
    "    # Road and Alley Surfaces\n",
    "    \"Grvl\": \"Gravel\",\n",
    "    \"Pave\": \"Paved\",\n",
    "    \"NA\": \"No Access\",  # Used for alleys and basements\n",
    "    # Lot Shape\n",
    "    \"Reg\": \"Regular\",\n",
    "    \"IR1\": \"Slightly Irregular\",\n",
    "    \"IR2\": \"Moderately Irregular\",\n",
    "    \"IR3\": \"Irregular\",\n",
    "    # Land Contour\n",
    "    \"Lvl\": \"Near Flat/Level\",\n",
    "    \"Bnk\": \"Banked\",\n",
    "    \"HLS\": \"Hillside\",\n",
    "    \"Low\": \"Depression\",\n",
    "    # Utilities\n",
    "    \"AllPub\": \"All Public Utilities\",\n",
    "    \"NoSewr\": \"No Sewer (Septic Tank)\",\n",
    "    \"NoSeWa\": \"No Sewer or Water\",\n",
    "    \"ELO\": \"Electricity Only\",\n",
    "    # Lot Config\n",
    "    \"Inside\": \"Inside Lot\",\n",
    "    \"Corner\": \"Corner Lot\",\n",
    "    \"CulDSac\": \"Cul-de-sac\",\n",
    "    \"FR2\": \"Frontage on 2 Sides\",\n",
    "    \"FR3\": \"Frontage on 3 Sides\",\n",
    "    # Land Slope\n",
    "    \"Gtl\": \"Gentle Slope\",\n",
    "    \"Mod\": \"Moderate Slope\",\n",
    "    \"Sev\": \"Severe Slope\",\n",
    "    # Condition (Condition1 & Condition2)\n",
    "    \"Artery\": \"Adjacent to Arterial Street\",\n",
    "    \"Feedr\": \"Adjacent to Feeder Street\",\n",
    "    \"Norm\": \"Normal\",\n",
    "    \"RRNn\": \"Near N-S Railroad\",\n",
    "    \"RRAn\": \"Adjacent to N-S Railroad\",\n",
    "    \"RRNe\": \"Near E-W Railroad\",\n",
    "    \"RRAe\": \"Adjacent to E-W Railroad\",\n",
    "    \"PosN\": \"Near Positive Off-site Feature\",\n",
    "    \"PosA\": \"Adjacent to Positive Off-site Feature\",\n",
    "    # Building Type\n",
    "    \"1Fam\": \"Single-family Detached\",\n",
    "    \"2FmCon\": \"Two-family Conversion\",\n",
    "    \"Duplx\": \"Duplex\",\n",
    "    \"TwnhsE\": \"Townhouse End Unit\",\n",
    "    \"TwnhsI\": \"Townhouse Inside Unit\",\n",
    "    # House Style\n",
    "    \"1Story\": \"One Story\",\n",
    "    \"1.5Fin\": \"One and Half Story Finished\",\n",
    "    \"1.5Unf\": \"One and Half Story Unfinished\",\n",
    "    \"2Story\": \"Two Story\",\n",
    "    \"2.5Fin\": \"Two and Half Story Finished\",\n",
    "    \"2.5Unf\": \"Two and Half Story Unfinished\",\n",
    "    \"SFoyer\": \"Split Foyer\",\n",
    "    \"SLvl\": \"Split Level\",\n",
    "    # Quality and Condition Ratings\n",
    "    \"Ex\": \"Excellent\",\n",
    "    \"Gd\": \"Good\",\n",
    "    \"TA\": \"Typical/Average\",\n",
    "    \"Fa\": \"Fair\",\n",
    "    \"Po\": \"Poor\",\n",
    "    # Basement Specific\n",
    "    \"Av\": \"Average Exposure\",\n",
    "    \"Mn\": \"Minimum Exposure\",\n",
    "    \"No\": \"No Exposure\",\n",
    "    \"GLQ\": \"Good Living Quarters\",\n",
    "    \"ALQ\": \"Average Living Quarters\",\n",
    "    \"BLQ\": \"Below Average Living Quarters\",\n",
    "    \"Rec\": \"Recreation Room\",\n",
    "    \"LwQ\": \"Low Quality\",\n",
    "    \"Unf\": \"Unfinished\",\n",
    "    # Heating\n",
    "    \"Floor\": \"Floor Furnace\",\n",
    "    \"GasA\": \"Gas Forced Warm Air\",\n",
    "    \"GasW\": \"Gas Hot Water or Steam\",\n",
    "    \"Grav\": \"Gravity Furnace\",\n",
    "    \"OthW\": \"Other Water Heater\",\n",
    "    \"Wall\": \"Wall Furnace\",\n",
    "    # Central Air\n",
    "    \"Y\": \"Yes\",\n",
    "    \"N\": \"No\",\n",
    "    # Electrical\n",
    "    \"SBrkr\": \"Standard Circuit Breakers\",\n",
    "    \"FuseA\": \"Fuse Box >60AMP + Romex\",\n",
    "    \"FuseF\": \"60AMP Fuse Box + Mostly Romex\",\n",
    "    \"FuseP\": \"60AMP + Mostly Knob & Tube\",\n",
    "    \"Mix\": \"Mixed Wiring\",\n",
    "    # Kitchen Quality\n",
    "    # Already mapped above: Ex, Gd, TA, Fa, Po\n",
    "    # Functional\n",
    "    \"Typ\": \"Typical Functionality\",\n",
    "    \"Min1\": \"Minor Deductions 1\",\n",
    "    \"Min2\": \"Minor Deductions 2\",\n",
    "    \"Mod\": \"Moderate Deductions\",\n",
    "    \"Maj1\": \"Major Deductions 1\",\n",
    "    \"Maj2\": \"Major Deductions 2\",\n",
    "    \"Sev\": \"Severely Damaged\",\n",
    "    \"Sal\": \"Salvage Only\",\n",
    "    # Fireplace Quality\n",
    "    # Already mapped above: Ex, Gd, TA, Fa, Po, NA\n",
    "    # Garage Type\n",
    "    \"2Types\": \"More than One Type\",\n",
    "    \"Attchd\": \"Attached\",\n",
    "    \"Basment\": \"Basement\",\n",
    "    \"BuiltIn\": \"Built-In\",\n",
    "}\n",
    "\n",
    "map_zoneamento = {\n",
    "    \"A\": \"Agriculture\",\n",
    "    \"C\": \"Commercial\",\n",
    "    \"FV\": \"Floating Village Residential\",\n",
    "    \"I\": \"Industrial\",\n",
    "    \"RH\": \"Residential High Density\",\n",
    "    \"RL\": \"Residential Low Density\",\n",
    "    \"RP\": \"Residential Low Density Park \",\n",
    "    \"RM\": \"Residential Medium Density\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "996fe342-51d5-4f00-bf7a-c0361fa5cb0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Primeiras Transformações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49c97a00-074a-417d-9b8a-dcd7f8ba52c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class MappingValues(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, dicionario, col: Optional[str] = None):\n",
    "        self.dicionario = dicionario\n",
    "        self.col = col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        if self.col is not None:\n",
    "            X_transformed[self.col] = X_transformed[self.col].replace(self.dicionario)\n",
    "        else:\n",
    "            X_transformed = X_transformed.replace(self.dicionario)\n",
    "        return X_transformed\n",
    "\n",
    "class numerical_only(BaseEstimator,TransformerMixin):\n",
    "    \"\"\"Retorna somente valores numéricos\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        X = X.copy()\n",
    "        X_transformed = X.select_dtypes(include=\"number\")\n",
    "        return X_transformed\n",
    "\n",
    "class NullReplacer(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,columns):\n",
    "        if isinstance(columns,str):\n",
    "            self.columns = [columns]\n",
    "        else:\n",
    "            self.columns = columns\n",
    "            \n",
    "    def fit(self,X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        for col in self.columns:\n",
    "            if col in X_transformed.columns:\n",
    "                X_transformed[col] = X_transformed[col].fillna(\"None\")\n",
    "                \n",
    "        return X_transformed\n",
    "\n",
    "lista = [\n",
    "    \"MiscFeature\",\"Alley\",\"Fence\",\"MasVnrType\",\"FireplaceQu\",\"GarageCond\",\"GarageQual\",\n",
    "    \"GarageFinish\",\"GarageCond\", \"GarageQual\", \"GarageFinish\",\"GarageType\",\"GarageYrBlt\", \n",
    "    \"BsmtExposure\", \"BsmtFinType2\", \"BsmtCond\",\"BsmtFinType1\", \"BsmtQual\",\"PoolQC\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9f34da5-094b-4047-81b8-95742b10f122",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Apenas dados numéricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29f15ef5-4403-424e-b5d0-f64f09b70124",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Regressão Linear básica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd18242d-8b8d-419c-a18d-4ddf75a3da72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Linear_regression_standard_scaler\"):\n",
    "\n",
    "    # Get your training and test data\n",
    "    X_train, X_test, y_train, y_test = get_data()\n",
    "\n",
    "    # Store column names and indices before transformation\n",
    "    train_index = X_train.index\n",
    "    test_index = X_test.index\n",
    "\n",
    "    # Save original columns (only works if numerical_only does not change them)\n",
    "    original_columns = X_train.columns\n",
    "\n",
    "    # Parameters for regression\n",
    "    fit_intercept = True\n",
    "    copy_X = True\n",
    "    n_jobs = None\n",
    "    positive = False\n",
    "\n",
    "    # Log parameters\n",
    "    params = {\n",
    "        \"fit_intercept\": fit_intercept,\n",
    "        \"copy_X\": copy_X,\n",
    "        \"n_jobs\": n_jobs,\n",
    "        \"positive\": positive,\n",
    "    }\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Define preprocessing pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('mappingvalues', MappingValues(value_mapping)),\n",
    "        ('numerical_only', numerical_only()),\n",
    "        ('replace_null', NullReplacer(lista)),\n",
    "        ('scaler', StandardScaler())   \n",
    "    ])\n",
    "\n",
    "    # Fit and transform training data\n",
    "    X_train_np = pipeline.fit_transform(X_train)\n",
    "    X_train = pd.DataFrame(X_train_np, index=train_index, columns=[f'feature_{i}' for i in range(X_train_np.shape[1])])\n",
    "    y_train = y_train.loc[train_index]\n",
    "\n",
    "    # Train model\n",
    "    lin_reg = LinearRegression(fit_intercept=fit_intercept, copy_X=copy_X, n_jobs=n_jobs, positive=positive)\n",
    "    lin_reg.fit(X_train, y_train)\n",
    "\n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(lin_reg, artifact_path=\"Linear_regression_standard_scaler\", input_example=X_train)\n",
    "\n",
    "    # Transform and prepare test data\n",
    "    X_test_np = pipeline.transform(X_test)\n",
    "    X_test_ = pd.DataFrame(X_test_np, index=test_index, columns=[f'feature_{i}' for i in range(X_test_np.shape[1])])\n",
    "    y_test = y_test.loc[test_index]\n",
    "\n",
    "    # Predict\n",
    "    predictions = lin_reg.predict(X_test_)\n",
    "\n",
    "    # Metrics\n",
    "    mse = mean_squared_error(y_test, predictions, squared=False)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    # Save predictions\n",
    "    predictions_df = pd.DataFrame({\"prediction\": predictions, \"real\": y_test})\n",
    "    predictions_df.to_csv(\"predictions.csv\", index=False)\n",
    "    mlflow.log_artifact(\"predictions.csv\")\n",
    "\n",
    "    # Residual plot\n",
    "    residuals = predictions - y_test\n",
    "    residuals_df = pd.DataFrame({\"residuals\": residuals})\n",
    "    sns.scatterplot(data=residuals_df, y=\"residuals\", x=residuals_df.index)\n",
    "    plt.xlabel(\"Observation\")\n",
    "    plt.ylabel(\"Residual\")\n",
    "    plt.title(\"Residuals\")\n",
    "    plt.savefig(\"residuals_plot.png\")\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(\"residuals_plot.png\")\n",
    "\n",
    "    # Real vs Predicted plot\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.scatterplot(x=y_test, y=predictions)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "    plt.xlabel(\"Valor real da casa\")\n",
    "    plt.ylabel(\"Preço previsto\")\n",
    "    plt.title(\"Real x Previsto\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"pred_vs_actual.png\")\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(\"pred_vs_actual.png\")\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\"\"\n",
    "    relatório de métricas de sucesso:\n",
    "    r2: {r2}\n",
    "    mse: {mse}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77f0efeb-4a99-490c-8359-697a4e261bde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class DataFramePolynomialFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, degree=2, include_bias=True, interaction_only=False):\n",
    "        self.degree = degree\n",
    "        self.include_bias = include_bias\n",
    "        self.interaction_only = interaction_only\n",
    "        self.poly = PolynomialFeatures(\n",
    "            degree=self.degree,\n",
    "            include_bias=self.include_bias,\n",
    "            interaction_only=self.interaction_only\n",
    "        )\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.poly.fit(X)\n",
    "        self.feature_names = self.poly.get_feature_names_out(input_features=X.columns)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_poly = self.poly.transform(X)\n",
    "        return pd.DataFrame(X_poly, columns=self.feature_names, index=X.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2475539b-cd6a-415c-a497-cf860625c514",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Ridge 3rd degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0de79c9e-cc38-4727-a68b-5dfde71f05e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_data()\n",
    "\n",
    "with mlflow.start_run(run_name=\"Ridge_numeric_3nd_degree_standard_scaler\"):\n",
    "    fit_intercept = True\n",
    "    copy_X = True\n",
    "    n_jobs = None\n",
    "    positive = False\n",
    "\n",
    "    params = {\"fit_intercetpt\": fit_intercept, \n",
    "              \"copy_X\": copy_X}\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"mappingvalues\", MappingValues(value_mapping)),\n",
    "            (\"numerical_only\", numerical_only()),\n",
    "            (\"replace_null\", NullReplacer(lista)),\n",
    "            (\"polynomial\",DataFramePolynomialFeatures(degree=3, include_bias=True, interaction_only=True))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    X_train = pipeline.fit_transform(X_train)\n",
    "    y_train = y_train.loc[X_train.index]\n",
    "\n",
    "    lin_reg = Ridge(fit_intercept=fit_intercept, copy_X=copy_X)\n",
    "    lin_reg.fit(X_train, y_train)\n",
    "\n",
    "    logged_model = mlflow.sklearn.log_model(\n",
    "        lin_reg, name=\"Ridge_numeric_3nd_degree_standard_scaler\", input_example=X_train\n",
    "    )\n",
    "\n",
    "    X_test = pipeline.transform(X_test)\n",
    "    y_test = y_test.loc[X_test.index]\n",
    "\n",
    "    predictions = lin_reg.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, predictions, squared=False)\n",
    "\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "\n",
    "    mlflow.log_metric(\"r2\",r2)\n",
    "\n",
    "    mlflow.log_artifact(\"predictions.csv\")\n",
    "    df = pd.DataFrame(data=predictions - y_test)\n",
    "\n",
    "    sns.scatterplot(data=df)\n",
    "    plt.xlabel(\"Observation\")\n",
    "    plt.ylabel(\"Residual\")\n",
    "    plt.title(\"Residuals\")\n",
    "    plt.savefig(\"residuals_plot.png\")\n",
    "    mlflow.log_artifact(\"residuals_plot.png\")\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.scatterplot(x=y_test, y=predictions)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "    plt.xlabel(\"Actual\")\n",
    "    plt.ylabel(\"Predicted\")\n",
    "    plt.title(\"Predicted vs Actual\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"pred_vs_actual.png\")\n",
    "    mlflow.log_artifact(\"pred_vs_actual.png\")\n",
    "    print(f\"\"\"\n",
    "    relatório de métricas de sucesso:\n",
    "    r2: {r2}\n",
    "    mse: {mse}\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "451a8759-bd26-45d9-90af-8551dbf82101",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "694b59fd-5753-4e2e-8551-8e5541f02ac6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "lasso_numeric"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get data\n",
    "X_train, X_test, y_train, y_test = get_data()\n",
    "\n",
    "# Save index before transformation\n",
    "train_index = X_train.index\n",
    "test_index = X_test.index\n",
    "\n",
    "with mlflow.start_run(run_name=\"Lasso_numeric_3nd_degree\"):\n",
    "\n",
    "    # Regression parameters\n",
    "    fit_intercept = True\n",
    "    copy_X = True\n",
    "    n_jobs = None\n",
    "    positive = False\n",
    "\n",
    "    # Log parameters (also fix typo: 'fit_intercetpt' → 'fit_intercept')\n",
    "    params = {\n",
    "        \"fit_intercept\": fit_intercept,\n",
    "        \"copy_X\": copy_X,\n",
    "        \"n_jobs\": n_jobs,\n",
    "        \"positive\": positive\n",
    "    }\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Define pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        (\"mappingvalues\", MappingValues(value_mapping)),\n",
    "        (\"numerical_only\", numerical_only()),\n",
    "        (\"replace_null\", NullReplacer(lista)),\n",
    "        (\"polynomial\", DataFramePolynomialFeatures(degree=3, include_bias=True, interaction_only=True))\n",
    "    ])\n",
    "\n",
    "    # Fit and transform training data\n",
    "    X_train_np = pipeline.fit_transform(X_train)\n",
    "    X_train = pd.DataFrame(X_train_np, index=train_index, columns=[f'feature_{i}' for i in range(X_train_np.shape[1])])\n",
    "    y_train = y_train.loc[train_index]\n",
    "\n",
    "    # Fit Lasso model\n",
    "    lin_reg = Lasso(fit_intercept=fit_intercept, copy_X=copy_X)\n",
    "    lin_reg.fit(X_train, y_train)\n",
    "\n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(\n",
    "        lin_reg,\n",
    "        artifact_path=\"Lasso_numeric_3nd_degree_numeric_only\",\n",
    "        input_example=X_train\n",
    "    )\n",
    "\n",
    "    # Transform test set\n",
    "    X_test_np = pipeline.transform(X_test)\n",
    "    X_test_ = pd.DataFrame(X_test_np, index=test_index, columns=[f'feature_{i}' for i in range(X_test_np.shape[1])])\n",
    "    y_test = y_test.loc[test_index]\n",
    "\n",
    "    # Predict\n",
    "    predictions = lin_reg.predict(X_test_)\n",
    "\n",
    "    # Metrics\n",
    "    mse = mean_squared_error(y_test, predictions, squared=False)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    # Save predictions to CSV\n",
    "    predictions_df = pd.DataFrame({\"prediction\": predictions, \"real\": y_test})\n",
    "    predictions_df.to_csv(\"predictions.csv\", index=False)\n",
    "    mlflow.log_artifact(\"predictions.csv\")\n",
    "\n",
    "    # Residual plot\n",
    "    residuals = predictions - y_test\n",
    "    residuals_df = pd.DataFrame({\"residuals\": residuals})\n",
    "    sns.scatterplot(data=residuals_df, y=\"residuals\", x=residuals_df.index)\n",
    "    plt.xlabel(\"Observation\")\n",
    "    plt.ylabel(\"Residual\")\n",
    "    plt.title(\"Residuals\")\n",
    "    plt.savefig(\"residuals_plot.png\")\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(\"residuals_plot.png\")\n",
    "\n",
    "    # Real vs Predicted plot\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.scatterplot(x=y_test, y=predictions)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "    plt.xlabel(\"Actual\")\n",
    "    plt.ylabel(\"Predicted\")\n",
    "    plt.title(\"Predicted vs Actual\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"pred_vs_actual.png\")\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(\"pred_vs_actual.png\")\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"\"\"\n",
    "    relatório de métricas de sucesso:\n",
    "    r2: {r2}\n",
    "    mse: {mse}\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "514910d5-8b40-4ced-98ad-20cc9292fe39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa15288c-bfa7-46db-814d-081b945e39fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Your custom transformers and dataset\n",
    "# from your_module import MappingValues, numerical_only, NullReplacer\n",
    "# from your_data_module import get_data, value_mapping, lista\n",
    "\n",
    "# Get data\n",
    "X_train, X_test, y_train, y_test = get_data()\n",
    "\n",
    "# Save index and columns before transformation\n",
    "train_index = X_train.index\n",
    "test_index = X_test.index\n",
    "\n",
    "with mlflow.start_run(run_name=\"Decision_tree_numeric_only\"):\n",
    "\n",
    "    # Hyperparameters\n",
    "    criterion = \"squared_error\"\n",
    "    max_depth = 10\n",
    "    min_samples_split = 15\n",
    "    min_samples_leaf = 5\n",
    "    random_state = 42\n",
    "\n",
    "    # Log parameters\n",
    "    params = {\n",
    "        \"criterion\": criterion,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"min_samples_split\": min_samples_split,\n",
    "        \"min_samples_leaf\": min_samples_leaf,\n",
    "        \"random_state\": random_state\n",
    "    }\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Define pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('mappingvalues', MappingValues(value_mapping)),\n",
    "        ('numerical_only', numerical_only()),\n",
    "        ('replace_null', NullReplacer(lista)),\n",
    "        ('scaler', StandardScaler())   \n",
    "    ])\n",
    "\n",
    "    # Fit and transform training data\n",
    "    X_train_np = pipeline.fit_transform(X_train)\n",
    "    X_train = pd.DataFrame(X_train_np, index=train_index, columns=[f'feature_{i}' for i in range(X_train_np.shape[1])])\n",
    "    y_train = y_train.loc[train_index]\n",
    "\n",
    "    # Train decision tree model\n",
    "    decision_tree = DecisionTreeRegressor(\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    decision_tree.fit(X_train, y_train)\n",
    "\n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(decision_tree, artifact_path=\"decision-tree-numeric_only\", input_example=X_train)\n",
    "\n",
    "    # Transform and prepare test data\n",
    "    X_test_np = pipeline.transform(X_test)\n",
    "    X_test_ = pd.DataFrame(X_test_np, index=test_index, columns=[f'feature_{i}' for i in range(X_test_np.shape[1])])\n",
    "    y_test = y_test.loc[test_index]\n",
    "\n",
    "    # Predict\n",
    "    predictions = decision_tree.predict(X_test_)\n",
    "\n",
    "    # Metrics\n",
    "    mse = mean_squared_error(y_test, predictions, squared=False)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    # Save predictions\n",
    "    pd.DataFrame({\"prediction\": predictions, \"real\": y_test}).to_csv(\"predictions.csv\", index=False)\n",
    "    mlflow.log_artifact(\"predictions.csv\")\n",
    "\n",
    "    # Residual plot\n",
    "    residuals = predictions - y_test\n",
    "    residuals_df = pd.DataFrame({\"residuals\": residuals})\n",
    "    sns.scatterplot(data=residuals_df, y=\"residuals\", x=residuals_df.index)\n",
    "    plt.xlabel(\"Observation\")\n",
    "    plt.ylabel(\"Residual\")\n",
    "    plt.title(\"Residuals\")\n",
    "    plt.savefig(\"residuals_plot.png\")\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(\"residuals_plot.png\")\n",
    "\n",
    "    # Real vs Predicted plot\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.scatterplot(x=y_test, y=predictions)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "    plt.xlabel(\"Actual\")\n",
    "    plt.ylabel(\"Predicted\")\n",
    "    plt.title(\"Predicted vs Actual\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"pred_vs_actual.png\")\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(\"pred_vs_actual.png\")\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"\"\"\n",
    "    relatório de métricas de sucesso:\n",
    "    r2: {r2}\n",
    "    mse: {mse}\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dff9c4d-a9e7-4741-b4bc-33822a50d3c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Random Fortest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2922f5c-9feb-4276-94e9-c9725f828337",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Random Forest"
    }
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = get_data()\n",
    "\n",
    "with mlflow.start_run(run_name=\"random_forest_numeric_only\"):\n",
    "\n",
    "   \n",
    "  n_estimators = 100\n",
    "  max_depth = 6\n",
    "  max_features = 3\n",
    "  params = {\n",
    "    \"n_estimators\": n_estimators,\n",
    "    \"max_depth\": max_depth,\n",
    "    \"max_features\": max_features\n",
    "  }\n",
    "\n",
    "  \n",
    "  mlflow.log_params(params)\n",
    "  \n",
    "  pipeline = Pipeline(steps=[\n",
    "        ('mappingvalues', MappingValues(value_mapping)),\n",
    "        ('numerical_only', numerical_only()),\n",
    "        ('replace_null', NullReplacer(lista)), ('scaler', StandardScaler())   \n",
    "    ])\n",
    "  \n",
    "  X_train = pipeline.fit_transform(X_train)\n",
    "  y_train = y_train.loc[X_train.index]\n",
    "\n",
    "  # Create and train model.\n",
    "  rf = RandomForestRegressor(n_estimators = n_estimators, max_depth = max_depth, max_features = max_features)\n",
    "  rf.fit(X_train, y_train)\n",
    "\n",
    "  \n",
    "  logged_model = mlflow.sklearn.log_model(rf, name=\"random-forest-numeric_only\", input_example=X_train)\n",
    "\n",
    "\n",
    "  X_test = pipeline.transform(X_test)\n",
    "  y_test = y_test.loc[X_test.index]\n",
    "\n",
    "  \n",
    "  predictions = rf.predict(X_test)\n",
    "\n",
    "  \n",
    "  mse = mean_squared_error(y_test, predictions, squared= False)\n",
    "  r2 = r2_score(y_test, predictions)  \n",
    "  \n",
    "  mlflow.log_metric(\"mse\", mse)\n",
    "  mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "  # Save the table of predicted values\n",
    "  np.savetxt('predictions.csv', predictions, delimiter=',')\n",
    "\n",
    "  \n",
    "  mlflow.log_artifact(\"predictions.csv\")\n",
    "\n",
    "  \n",
    "  df = pd.DataFrame(data = predictions - y_test)\n",
    "  \n",
    "  sns.scatterplot(data=df)\n",
    "  plt.xlabel(\"Observation\")\n",
    "  plt.ylabel(\"Residual\")\n",
    "  plt.title(\"Residuals\")\n",
    "  plt.savefig(\"residuals_plot.png\")\n",
    "  mlflow.log_artifact(\"residuals_plot.png\")\n",
    "\n",
    "  plt.figure(figsize=(8, 5))\n",
    "  sns.scatterplot(x=y_test, y=predictions)\n",
    "  plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "  plt.xlabel(\"Actual\")\n",
    "  plt.ylabel(\"Predicted\")\n",
    "  plt.title(\"Predicted vs Actual\")\n",
    "  plt.grid(True)\n",
    "  plt.tight_layout()\n",
    "  plt.savefig(\"pred_vs_actual.png\")\n",
    "  mlflow.log_artifact(\"pred_vs_actual.png\")\n",
    "  print(f\"\"\"\n",
    "    relatório de métricas de sucesso:\n",
    "    r2: {r2}\n",
    "    mse: {mse}\n",
    "    \"\"\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "STANDARD"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5711032330399772,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "(WIP) Tratamento dos dados - EDA",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "GreenGarden",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

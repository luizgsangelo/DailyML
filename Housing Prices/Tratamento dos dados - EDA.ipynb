{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c44ab71-956f-4a76-970f-fbabae76b708",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-feature-engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5696d52c-7095-44a8-bb08-0e49f8aba899",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from typing import Optional\n",
    "from sklearn.impute import KNNImputer\n",
    "import seaborn as sns \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge \n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d07b5d1-9d3c-4147-a456-29b62610aafc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    df = spark.read.table(\"workspace.ml_datasets.house_prediction_train\")\n",
    "    train = df.toPandas()\n",
    "    X = train.drop(columns=\"SalePrice\")\n",
    "    y = train[\"SalePrice\"]\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,train_size=0.8)\n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "X_train,X_test,y_train,y_test = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4932899e-6591-4806-9a6d-910d909deaae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7889cb8-82f0-44f9-83b4-df2bf97ea423",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "413636d1-9508-4557-a27e-73a7d3921ce9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Mapping utilizado com base em reposta de IA para tornar os nomes mais descritivos:\n",
    "value_mapping = {\n",
    "    # Road and Alley Surfaces\n",
    "    \"Grvl\": \"Gravel\",\n",
    "    \"Pave\": \"Paved\",\n",
    "    \"NA\": \"No Access\",  # Used for alleys and basements\n",
    "    # Lot Shape\n",
    "    \"Reg\": \"Regular\",\n",
    "    \"IR1\": \"Slightly Irregular\",\n",
    "    \"IR2\": \"Moderately Irregular\",\n",
    "    \"IR3\": \"Irregular\",\n",
    "    # Land Contour\n",
    "    \"Lvl\": \"Near Flat/Level\",\n",
    "    \"Bnk\": \"Banked\",\n",
    "    \"HLS\": \"Hillside\",\n",
    "    \"Low\": \"Depression\",\n",
    "    # Utilities\n",
    "    \"AllPub\": \"All Public Utilities\",\n",
    "    \"NoSewr\": \"No Sewer (Septic Tank)\",\n",
    "    \"NoSeWa\": \"No Sewer or Water\",\n",
    "    \"ELO\": \"Electricity Only\",\n",
    "    # Lot Config\n",
    "    \"Inside\": \"Inside Lot\",\n",
    "    \"Corner\": \"Corner Lot\",\n",
    "    \"CulDSac\": \"Cul-de-sac\",\n",
    "    \"FR2\": \"Frontage on 2 Sides\",\n",
    "    \"FR3\": \"Frontage on 3 Sides\",\n",
    "    # Land Slope\n",
    "    \"Gtl\": \"Gentle Slope\",\n",
    "    \"Mod\": \"Moderate Slope\",\n",
    "    \"Sev\": \"Severe Slope\",\n",
    "    # Condition (Condition1 & Condition2)\n",
    "    \"Artery\": \"Adjacent to Arterial Street\",\n",
    "    \"Feedr\": \"Adjacent to Feeder Street\",\n",
    "    \"Norm\": \"Normal\",\n",
    "    \"RRNn\": \"Near N-S Railroad\",\n",
    "    \"RRAn\": \"Adjacent to N-S Railroad\",\n",
    "    \"RRNe\": \"Near E-W Railroad\",\n",
    "    \"RRAe\": \"Adjacent to E-W Railroad\",\n",
    "    \"PosN\": \"Near Positive Off-site Feature\",\n",
    "    \"PosA\": \"Adjacent to Positive Off-site Feature\",\n",
    "    # Building Type\n",
    "    \"1Fam\": \"Single-family Detached\",\n",
    "    \"2FmCon\": \"Two-family Conversion\",\n",
    "    \"Duplx\": \"Duplex\",\n",
    "    \"TwnhsE\": \"Townhouse End Unit\",\n",
    "    \"TwnhsI\": \"Townhouse Inside Unit\",\n",
    "    # House Style\n",
    "    \"1Story\": \"One Story\",\n",
    "    \"1.5Fin\": \"One and Half Story Finished\",\n",
    "    \"1.5Unf\": \"One and Half Story Unfinished\",\n",
    "    \"2Story\": \"Two Story\",\n",
    "    \"2.5Fin\": \"Two and Half Story Finished\",\n",
    "    \"2.5Unf\": \"Two and Half Story Unfinished\",\n",
    "    \"SFoyer\": \"Split Foyer\",\n",
    "    \"SLvl\": \"Split Level\",\n",
    "    # Quality and Condition Ratings\n",
    "    \"Ex\": \"Excellent\",\n",
    "    \"Gd\": \"Good\",\n",
    "    \"TA\": \"Typical/Average\",\n",
    "    \"Fa\": \"Fair\",\n",
    "    \"Po\": \"Poor\",\n",
    "    # Basement Specific\n",
    "    \"Av\": \"Average Exposure\",\n",
    "    \"Mn\": \"Minimum Exposure\",\n",
    "    \"No\": \"No Exposure\",\n",
    "    \"GLQ\": \"Good Living Quarters\",\n",
    "    \"ALQ\": \"Average Living Quarters\",\n",
    "    \"BLQ\": \"Below Average Living Quarters\",\n",
    "    \"Rec\": \"Recreation Room\",\n",
    "    \"LwQ\": \"Low Quality\",\n",
    "    \"Unf\": \"Unfinished\",\n",
    "    # Heating\n",
    "    \"Floor\": \"Floor Furnace\",\n",
    "    \"GasA\": \"Gas Forced Warm Air\",\n",
    "    \"GasW\": \"Gas Hot Water or Steam\",\n",
    "    \"Grav\": \"Gravity Furnace\",\n",
    "    \"OthW\": \"Other Water Heater\",\n",
    "    \"Wall\": \"Wall Furnace\",\n",
    "    # Central Air\n",
    "    \"Y\": \"Yes\",\n",
    "    \"N\": \"No\",\n",
    "    # Electrical\n",
    "    \"SBrkr\": \"Standard Circuit Breakers\",\n",
    "    \"FuseA\": \"Fuse Box >60AMP + Romex\",\n",
    "    \"FuseF\": \"60AMP Fuse Box + Mostly Romex\",\n",
    "    \"FuseP\": \"60AMP + Mostly Knob & Tube\",\n",
    "    \"Mix\": \"Mixed Wiring\",\n",
    "    # Kitchen Quality\n",
    "    # Already mapped above: Ex, Gd, TA, Fa, Po\n",
    "    # Functional\n",
    "    \"Typ\": \"Typical Functionality\",\n",
    "    \"Min1\": \"Minor Deductions 1\",\n",
    "    \"Min2\": \"Minor Deductions 2\",\n",
    "    \"Mod\": \"Moderate Deductions\",\n",
    "    \"Maj1\": \"Major Deductions 1\",\n",
    "    \"Maj2\": \"Major Deductions 2\",\n",
    "    \"Sev\": \"Severely Damaged\",\n",
    "    \"Sal\": \"Salvage Only\",\n",
    "    # Fireplace Quality\n",
    "    # Already mapped above: Ex, Gd, TA, Fa, Po, NA\n",
    "    # Garage Type\n",
    "    \"2Types\": \"More than One Type\",\n",
    "    \"Attchd\": \"Attached\",\n",
    "    \"Basment\": \"Basement\",\n",
    "    \"BuiltIn\": \"Built-In\",\n",
    "}\n",
    "\n",
    "map_zoneamento = {\n",
    "    \"A\": \"Agriculture\",\n",
    "    \"C\": \"Commercial\",\n",
    "    \"FV\": \"Floating Village Residential\",\n",
    "    \"I\": \"Industrial\",\n",
    "    \"RH\": \"Residential High Density\",\n",
    "    \"RL\": \"Residential Low Density\",\n",
    "    \"RP\": \"Residential Low Density Park \",\n",
    "    \"RM\": \"Residential Medium Density\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49c97a00-074a-417d-9b8a-dcd7f8ba52c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class MappingValues(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, dicionario, col: Optional[str] = None):\n",
    "        self.dicionario = dicionario\n",
    "        self.col = col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        if self.col is not None:\n",
    "            X_transformed[self.col] = X_transformed[self.col].replace(self.dicionario)\n",
    "        else:\n",
    "            X_transformed = X_transformed.replace(self.dicionario)\n",
    "        return X_transformed\n",
    "\n",
    "class numerical_only(BaseEstimator,TransformerMixin):\n",
    "    \"\"\"Retorna somente valores numéricos\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        X = X.copy()\n",
    "        X_transformed = X.select_dtypes(include=\"number\")\n",
    "        return X_transformed\n",
    "\n",
    "class NullReplacer(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,columns):\n",
    "        if isinstance(columns,str):\n",
    "            self.columns = [columns]\n",
    "        else:\n",
    "            self.columns = columns\n",
    "            \n",
    "    def fit(self,X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        for col in self.columns:\n",
    "            if col in X_transformed.columns:\n",
    "                X_transformed[col] = X_transformed[col].fillna(\"None\")\n",
    "                \n",
    "        return X_transformed\n",
    "\n",
    "lista = [\n",
    "    \"MiscFeature\",\"Alley\",\"Fence\",\"MasVnrType\",\"FireplaceQu\",\"GarageCond\",\"GarageQual\",\n",
    "    \"GarageFinish\",\"GarageCond\", \"GarageQual\", \"GarageFinish\",\"GarageType\",\"GarageYrBlt\", \n",
    "    \"BsmtExposure\", \"BsmtFinType2\", \"BsmtCond\",\"BsmtFinType1\", \"BsmtQual\",\"PoolQC\"\n",
    "]\n",
    "\n",
    "\n",
    "## knn = KNNImputer()\n",
    "## X_train[\"LotFrontage\"] = knn.fit_transform(X_train[[\"LotFrontage\"]])\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('mappingvalues', MappingValues(value_mapping)),\n",
    "    ('numerical_only', numerical_only()),\n",
    "    ('replace_null', NullReplacer(lista)),\n",
    "])\n",
    "\n",
    "X_train = pipeline.fit_transform(X_train)\n",
    "X_train.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ed34e66-e9bf-4266-9de6-048f1b922725",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_train = y_train.loc[X_train.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9f34da5-094b-4047-81b8-95742b10f122",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sem feature engineering, sem variaveis categoricas, com alta dimensionalidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd18242d-8b8d-419c-a18d-4ddf75a3da72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"LinReg_numeric_only_v2\"):\n",
    "\n",
    "    # Set the model parameters. \n",
    "    fit_intercept = True\n",
    "    copy_X = True\n",
    "    n_jobs = None\n",
    "    positive = False\n",
    "\n",
    "\n",
    "    params = {\n",
    "    \"fit_intercetpt\": fit_intercept,\n",
    "    \"copy_X\": copy_X,\n",
    "    \"n_jobs\": n_jobs,\n",
    "    \"positive\": positive,\n",
    "    }\n",
    "    \n",
    "\n",
    "    # Log the model parameters used for this run.\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    pipeline = Pipeline(steps=[\n",
    "      ('mappingvalues', MappingValues(value_mapping)),\n",
    "      ('numerical_only', numerical_only()),\n",
    "      ('replace_null', NullReplacer(lista)),\n",
    "    ])\n",
    "\n",
    "    X_train = pipeline.fit_transform(X_train)\n",
    "    y_train = y_train.loc[X_train.index]\n",
    "\n",
    "    # Create and train model.\n",
    "    lin_reg = LinearRegression(fit_intercept= fit_intercept,  copy_X = copy_X, n_jobs = n_jobs, positive =positive)\n",
    "    \n",
    "    lin_reg.fit(X_train, y_train)\n",
    "\n",
    "    # Log the model create by this run, creating a Logged Model which inherits the parameters\n",
    "    logged_model = mlflow.sklearn.log_model(lin_reg, name=\"Linear_regression_numerical_only\", input_example=X_train)\n",
    "\n",
    "    X_test = pipeline.transform(X_test)\n",
    "    y_test = y_test.loc[X_test.index]\n",
    "\n",
    "    # Use the model to make predictions on the test dataset.\n",
    "    predictions = lin_reg.predict(X_test)\n",
    "\n",
    "    # Define a metric to use to evaluate the model.\n",
    "    mse = mean_squared_error(y_test, predictions,squared=False)\n",
    "\n",
    "    # Log the value of the metric from this run, linking to the logged model\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    \n",
    "    # Log the saved table as an artifact\n",
    "    mlflow.log_artifact(\"predictions.csv\")\n",
    "\n",
    "    # Convert the residuals to a pandas dataframe to take advantage of graphics capabilities\n",
    "    df = pd.DataFrame(data = predictions - y_test)\n",
    "\n",
    "    # Create a plot of residuals\n",
    "    sns.scatterplot(data=df)\n",
    "    plt.xlabel(\"Observation\")\n",
    "    plt.ylabel(\"Residual\")\n",
    "    plt.title(\"Residuals\")\n",
    "\n",
    "    # Save the plot and log it as an artifact\n",
    "    plt.savefig(\"residuals_plot.png\")\n",
    "    mlflow.log_artifact(\"residuals_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e44db753-2ec3-471a-8ad8-c6f1b96f7daa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = get_data()\n",
    "\n",
    "with mlflow.start_run(run_name=\"Ridge_numeric\"):\n",
    "\n",
    "    # Set the model parameters. \n",
    "    fit_intercept = True\n",
    "    copy_X = True\n",
    "    n_jobs = None\n",
    "    positive = False\n",
    "\n",
    "    params = {\n",
    "    \"fit_intercetpt\": fit_intercept,\n",
    "    \"copy_X\": copy_X\n",
    "    }\n",
    "\n",
    "    # Log the model parameters used for this run.\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    pipeline = Pipeline(steps=[\n",
    "      ('mappingvalues', MappingValues(value_mapping)),\n",
    "      ('numerical_only', numerical_only()),\n",
    "      ('replace_null', NullReplacer(lista))\n",
    "    ])\n",
    "\n",
    "    X_train = pipeline.fit_transform(X_train)\n",
    "    y_train = y_train.loc[X_train.index]\n",
    "\n",
    "    # Create and train model.\n",
    "    lin_reg = Ridge(fit_intercept= fit_intercept,  copy_X = copy_X)\n",
    "    \n",
    "    lin_reg.fit(X_train, y_train)\n",
    "\n",
    "    # Log the model create by this run, creating a Logged Model which inherits the parameters\n",
    "    logged_model = mlflow.sklearn.log_model(lin_reg, name=\"Linear_regression_numerical_only\", input_example=X_train)\n",
    "\n",
    "    X_test = pipeline.transform(X_test)\n",
    "    y_test = y_test.loc[X_test.index]\n",
    "\n",
    "    # Use the model to make predictions on the test dataset.\n",
    "    predictions = lin_reg.predict(X_test)\n",
    "\n",
    "    # Define a metric to use to evaluate the model.\n",
    "    mse = mean_squared_error(y_test, predictions,squared=False)\n",
    "\n",
    "    # Log the value of the metric from this run, linking to the logged model\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    \n",
    "    # Log the saved table as an artifact\n",
    "    mlflow.log_artifact(\"predictions.csv\")\n",
    "\n",
    "    # Convert the residuals to a pandas dataframe to take advantage of graphics capabilities\n",
    "    df = pd.DataFrame(data = predictions - y_test)\n",
    "\n",
    "    # Create a plot of residuals\n",
    "    sns.scatterplot(data=df)\n",
    "    plt.xlabel(\"Observation\")\n",
    "    plt.ylabel(\"Residual\")\n",
    "    plt.title(\"Residuals\")\n",
    "\n",
    "    # Save the plot and log it as an artifact\n",
    "    plt.savefig(\"residuals_plot.png\")\n",
    "    mlflow.log_artifact(\"residuals_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "694b59fd-5753-4e2e-8551-8e5541f02ac6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = get_data()\n",
    "\n",
    "with mlflow.start_run(run_name=\"Lasso_numeric\"):\n",
    "\n",
    "    # Set the model parameters. \n",
    "    fit_intercept = True\n",
    "    copy_X = True\n",
    "    n_jobs = None\n",
    "    positive = False\n",
    "\n",
    "    params = {\n",
    "    \"fit_intercetpt\": fit_intercept,\n",
    "    \"copy_X\": copy_X\n",
    "    }\n",
    "\n",
    "    # Log the model parameters used for this run.\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    pipeline = Pipeline(steps=[\n",
    "      ('mappingvalues', MappingValues(value_mapping)),\n",
    "      ('numerical_only', numerical_only()),\n",
    "      ('replace_null', NullReplacer(lista))\n",
    "    ])\n",
    "\n",
    "    X_train = pipeline.fit_transform(X_train)\n",
    "    y_train = y_train.loc[X_train.index]\n",
    "\n",
    "    # Create and train model.\n",
    "    lin_reg = Lasso(fit_intercept= fit_intercept,  copy_X = copy_X)\n",
    "    \n",
    "    lin_reg.fit(X_train, y_train)\n",
    "\n",
    "    # Log the model create by this run, creating a Logged Model which inherits the parameters\n",
    "    logged_model = mlflow.sklearn.log_model(lin_reg, name=\"Lasso_regression_numerical_only\", input_example=X_train)\n",
    "\n",
    "    X_test = pipeline.transform(X_test)\n",
    "    y_test = y_test.loc[X_test.index]\n",
    "\n",
    "    # Use the model to make predictions on the test dataset.\n",
    "    predictions = lin_reg.predict(X_test)\n",
    "\n",
    "    # Define a metric to use to evaluate the model.\n",
    "    mse = mean_squared_error(y_test, predictions,squared=False)\n",
    "\n",
    "    # Log the value of the metric from this run, linking to the logged model\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    \n",
    "    # Log the saved table as an artifact\n",
    "    mlflow.log_artifact(\"predictions.csv\")\n",
    "\n",
    "    # Convert the residuals to a pandas dataframe to take advantage of graphics capabilities\n",
    "    df = pd.DataFrame(data = predictions - y_test)\n",
    "\n",
    "    # Create a plot of residuals\n",
    "    sns.scatterplot(data=df)\n",
    "    plt.xlabel(\"Observation\")\n",
    "    plt.ylabel(\"Residual\")\n",
    "    plt.title(\"Residuals\")\n",
    "\n",
    "    # Save the plot and log it as an artifact\n",
    "    plt.savefig(\"residuals_plot.png\")\n",
    "    mlflow.log_artifact(\"residuals_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2922f5c-9feb-4276-94e9-c9725f828337",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with mlflow.start_run(run_name=\"model_training_v1\"):\n",
    "\n",
    "  # Set the model parameters. \n",
    "  n_estimators = 100\n",
    "  max_depth = 6\n",
    "  max_features = 3\n",
    "  params = {\n",
    "    \"n_estimators\": n_estimators,\n",
    "    \"max_depth\": max_depth,\n",
    "    \"max_features\": max_features\n",
    "  }\n",
    "\n",
    "  # Log the model parameters used for this run.\n",
    "  mlflow.log_params(params)\n",
    "\n",
    "  # Create and train model.\n",
    "  rf = RandomForestRegressor(n_estimators = n_estimators, max_depth = max_depth, max_features = max_features)\n",
    "  rf.fit(X_train, y_train)\n",
    "\n",
    "  # Log the model create by this run, creating a Logged Model which inherits the parameters\n",
    "  logged_model = mlflow.sklearn.log_model(rf, name=\"random-forest-model\", input_example=X_train)\n",
    "\n",
    "  pipeline = Pipeline(steps=[\n",
    "        ('mappingvalues', MappingValues(value_mapping)),\n",
    "        ('numerical_only', numerical_only()),\n",
    "        ('replace_null', NullReplacer(lista)),\n",
    "    ])\n",
    "\n",
    "  X_test = pipeline.transform(X_test)\n",
    "  y_test = y_test.loc[X_test.index]\n",
    "\n",
    "  # Use the model to make predictions on the test dataset.\n",
    "  predictions = rf.predict(X_test)\n",
    "\n",
    "  # Define a metric to use to evaluate the model.\n",
    "  mse = mean_squared_error(y_test, predictions)\n",
    "    \n",
    "  # Log the value of the metric from this run, linking to the logged model\n",
    "  mlflow.log_metric(\"mse\", mse)\n",
    "\n",
    "  # Save the table of predicted values\n",
    "  np.savetxt('predictions.csv', predictions, delimiter=',')\n",
    "\n",
    "  # Log the saved table as an artifact\n",
    "  mlflow.log_artifact(\"predictions.csv\")\n",
    "\n",
    "  # Convert the residuals to a pandas dataframe to take advantage of graphics capabilities\n",
    "  df = pd.DataFrame(data = predictions - y_test)\n",
    "\n",
    "  # Create a plot of residuals\n",
    "  sns.scatterplot(data=df)\n",
    "  plt.xlabel(\"Observation\")\n",
    "  plt.ylabel(\"Residual\")\n",
    "  plt.title(\"Residuals\")\n",
    "\n",
    "  # Save the plot and log it as an artifact\n",
    "  plt.savefig(\"residuals_plot.png\")\n",
    "  mlflow.log_artifact(\"residuals_plot.png\")\n",
    "  df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6434181f-8116-4f27-bd6b-59306eb40a09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Adicionando nova modalidade com features cateogricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e0dbe49-3684-475d-bb78-649f91799b51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.table(\"workspace.ml_datasets.house_prediction_train\")\n",
    "train = df.toPandas()\n",
    "train.info()\n",
    "X = train.drop(columns=\"SalePrice\")\n",
    "y = train[\"SalePrice\"]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbd24bc3-cad4-4f3b-9a01-b6b2c5206ede",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_clean = X_train.dropna()\n",
    "y_train_v1 = y_train.loc[df_clean.index]\n",
    "\n",
    "\n",
    "selected_cols = df_clean.select_dtypes(include=\"object\").columns\n",
    "\n",
    "\n",
    "encoded_df = pd.get_dummies(df_clean[selected_cols], drop_first=True)\n",
    "\n",
    "\n",
    "X_train_v1 = encoded_df\n",
    "model = RandomForestRegressor(n_estimators=1000, random_state=42, max_depth=6)\n",
    "model.fit(X_train_v1, y_train_v1)\n",
    "\n",
    "\n",
    "importances = pd.Series(model.feature_importances_, index=X_train_v1.columns)\n",
    "top_features = importances.sort_values(ascending=False).head(10)\n",
    "\n",
    "\n",
    "top_original_cols = set([col.split('_')[0] for col in top_features.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b3016ad-3b1e-4120-bde1-e5c0f9ca4a5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder,OneHotEncoder,StandardScaler\n",
    "\n",
    "\n",
    "categoricas = X_train[top_original_cols]\n",
    "categoricas.head()\n",
    "ordinal_columns = [\"BsmtExposure\",\"BsmtQual\",\"ExterQual\",\"KitchenQual\",\"FireplaceQu\"]\n",
    "cat_columns = [x for x in categoricas.columns if x not in ordinal_columns]\n",
    "\n",
    "class OrdinalColumns(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,lista_ordinais):\n",
    "        self.lista_ordinais = lista_ordinais \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        Ordinal = OrdinalEncoder()\n",
    "        X_transformed = X.copy()\n",
    "        for col in self.lista_ordinais:\n",
    "            X_transformed[col] = Ordinal.fit_transform(X_transformed[[col]])\n",
    "        return X_transformed\n",
    "\n",
    "class CatColumns(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,lista_categoricas):\n",
    "        self.lista_categoricas = lista_categoricas \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        OneHot = OneHotEncoder()\n",
    "        X_transformed = X.copy()\n",
    "        for col in self.lista_categoricas:\n",
    "            X_transformed[col] = OneHot.fit_transform(X_transformed[[col]])\n",
    "        return X_transformed\n",
    "\n",
    "class NumericAndInt(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        X_transformed = X.copy()\n",
    "        colunas_numericas = X_transformed.select_dtypes(include=\"number\").columns\n",
    "        lista_final = colunas_numericas + ordinal_columns + cat_columns\n",
    "        X_transformed = X_transformed[lista_final]\n",
    "        return X_transformed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f58ae36e-8baf-47d1-aeac-7b03b70b3dce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ordinal_columns = [\"BsmtQual\", \"ExterQual\", \"KitchenQual\"]\n",
    "cat_columns = [x for x in X_train.columns if x not in ordinal_columns and X_train[x].dtype == \"object\"]\n",
    "\n",
    "class OrdinalColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lista_ordinais):\n",
    "        self.lista_ordinais = lista_ordinais\n",
    "        self.encoder = OrdinalEncoder()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.encoder.fit(X[self.lista_ordinais])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        X_transformed[self.lista_ordinais] = self.encoder.transform(X[self.lista_ordinais])\n",
    "        return X_transformed\n",
    "\n",
    "class CatColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lista_categoricas):\n",
    "        self.lista_categoricas = lista_categoricas\n",
    "        self.encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.encoder.fit(X[self.lista_categoricas])\n",
    "        self.feature_names = self.encoder.get_feature_names_out(self.lista_categoricas)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        encoded = self.encoder.transform(X[self.lista_categoricas])\n",
    "        encoded_df = pd.DataFrame(encoded, columns=self.feature_names, index=X.index)\n",
    "        X_transformed = X_transformed.drop(columns=self.lista_categoricas)\n",
    "        X_transformed = pd.concat([X_transformed, encoded_df], axis=1)\n",
    "        return X_transformed\n",
    "\n",
    "class NumericAndInt(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.select_dtypes(include=\"number\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"cat+int\"):\n",
    "\n",
    "    n_estimators = 100\n",
    "    max_depth = 6\n",
    "    max_features = 3\n",
    "    params = {\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"max_features\": max_features\n",
    "    }\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('mappingvalues', MappingValues(value_mapping)),\n",
    "        ('ordinal_columns', OrdinalColumns(ordinal_columns)),\n",
    "        ('replace_null', NullReplacer(lista)),\n",
    "        (\"number_only\",numerical_only()),\n",
    "        (\"standard_scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # Apply transformation\n",
    "    X_train_transformed = pipeline.fit_transform(X_train)\n",
    "    y_train = y_train.loc[X_train.index]\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features)\n",
    "    rf.fit(X_train_transformed, y_train)\n",
    "\n",
    "    mlflow.sklearn.log_model(rf, name=\"random-forest-model\", input_example=X_train_transformed)\n",
    "\n",
    "    X_test_transformed = pipeline.transform(X_test)\n",
    "    y_test = y_test.loc[X_test.index]\n",
    "\n",
    "    predictions = rf.predict(X_test_transformed)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "\n",
    "    np.savetxt('predictions.csv', predictions, delimiter=',')\n",
    "    mlflow.log_artifact(\"predictions.csv\")\n",
    "\n",
    "    df = pd.DataFrame(data=predictions - y_test)\n",
    "    sns.scatterplot(data=df)\n",
    "    plt.xlabel(\"Observation\")\n",
    "    plt.ylabel(\"Residual\")\n",
    "    plt.title(\"Residuals\")\n",
    "    plt.savefig(\"residuals_plot.png\")\n",
    "    mlflow.log_artifact(\"residuals_plot.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cd19968-71dc-4de7-abc8-aa939ed70164",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "categoricas[\"BsmtExposure\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a68a312-2330-4582-9c5c-72dbbdacbce4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "list_of_ordinal_columns = [x for x in X_train.columns if \"Qual\" in x[-4:] or \"Cond\" in x[-4:]]\n",
    "teste = X_train[list_of_ordinal_columns]\n",
    "teste.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03574063-7c6a-45b6-b4db-81893f6fd6af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "a = \"Condition2\"\n",
    "a[-4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0022913-827c-45b4-b09f-dabcafdb8678",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Verificação de qualidade de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6c76766-1305-4418-9b86-b43db214b4e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"v1_LinReg_numerical_only\"):\n",
    "\n",
    "\n",
    "\n",
    "# Set the params for linear_gression\n",
    "params = {\n",
    "  \"n_estimators\": n_estimators,\n",
    "  \"max_depth\": max_depth,\n",
    "  \"max_features\": max_features\n",
    "}\n",
    "\n",
    "# Log the model parameters used for this run.\n",
    "mlflow.log_params(params)\n",
    "\n",
    "# Create and train model.\n",
    "rf = RandomForestRegressor(n_estimators = n_estimators, max_depth = max_depth, max_features = max_features)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Log the model create by this run, creating a Logged Model which inherits the parameters\n",
    "logged_model = mlflow.sklearn.log_model(rf, name=\"random-forest-model\", input_example=X_train)\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "      ('mappingvalues', MappingValues(value_mapping)),\n",
    "      ('numerical_only', numerical_only()),\n",
    "      ('replace_null', NullReplacer(lista)),\n",
    "  ])\n",
    "\n",
    "X_test = pipeline.transform(X_test)\n",
    "y_test = y_test.loc[X_test.index]\n",
    "\n",
    "# Use the model to make predictions on the test dataset.\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "# Define a metric to use to evaluate the model.\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "  \n",
    "# Log the value of the metric from this run, linking to the logged model\n",
    "mlflow.log_metric(\"mse\", mse)\n",
    "\n",
    "# Save the table of predicted values\n",
    "np.savetxt('predictions.csv', predictions, delimiter=',')\n",
    "\n",
    "# Log the saved table as an artifact\n",
    "mlflow.log_artifact(\"predictions.csv\")\n",
    "\n",
    "# Convert the residuals to a pandas dataframe to take advantage of graphics capabilities\n",
    "df = pd.DataFrame(data = predictions - y_test)\n",
    "\n",
    "# Create a plot of residuals\n",
    "sns.scatterplot(data=df)\n",
    "plt.xlabel(\"Observation\")\n",
    "plt.ylabel(\"Residual\")\n",
    "plt.title(\"Residuals\")\n",
    "\n",
    "# Save the plot and log it as an artifact\n",
    "plt.savefig(\"residuals_plot.png\")\n",
    "mlflow.log_artifact(\"residuals_plot.png\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ba8aef6-20ad-4798-bd60-83b8caa428aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "n = len(X_train.count())\n",
    "nulos = X_train.isnull().sum().reset_index()\n",
    "nulos[\"relativa\"] = round(nulos[0]/n,0)\n",
    "nulos.sort_values(by=\"relativa\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc999861-7dca-4ebd-8d48-e95de3fef79c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin    \n",
    "\n",
    "class NullReplacer(BaseEstimator,TransformerMixin):\n",
    "    \n",
    "    def __init__(self,columns):\n",
    "        if isinstance(columns,str):\n",
    "            self.columns = [columns]\n",
    "        else:\n",
    "            self.columns = columns\n",
    "            \n",
    "    def fit(self,X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        for col in self.columns:\n",
    "            if col in X_transformed.columns:\n",
    "                X_transformed[col] = X_transformed[col].fillna(\"None\")\n",
    "                \n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d984064f-67ff-4afb-a0bf-e3376a67f512",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb2f583e-2e09-4a2f-9972-f11a4e5b0282",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lista = [\n",
    "    \"MiscFeature\",\"Alley\",\"Fence\",\"MasVnrType\",\"FireplaceQu\",\"GarageCond\",\"GarageQual\",\n",
    "    \"GarageFinish\",\"GarageCond\", \"GarageQual\", \"GarageFinish\",\"GarageType\",\"GarageYrBlt\", \n",
    "    \"BsmtExposure\", \"BsmtFinType2\", \"BsmtCond\",\"BsmtFinType1\", \"BsmtQual\",\"PoolQC\"\n",
    "]\n",
    "\n",
    "null_replacer = NullReplacer(lista)\n",
    "for col in lista:\n",
    "    X_train = null_replacer.transform(X_train)\n",
    "\n",
    "X_train.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "147796d4-13c6-422d-b95f-139aed955541",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "knn = KNNImputer()\n",
    "X_train[\"LotFrontage\"] = knn.fit_transform(X_train[[\"LotFrontage\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0eb9d3d8-1aef-4d71-a8ad-7614eeb6b9b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5f59d00-2d9c-462f-bc29-289c1657480e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "530a330f-3e40-489e-8b12-95a00bb7edd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train.hist(figsize=(12,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6b0baf1-af8f-4db3-9023-39b1d7ef8d67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_train.shape\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f38845e5-672a-43bc-83c6-a378e7b09a4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_train = y_train.loc[X_train.index]\n",
    "\n",
    "\n",
    "def show_plot():   \n",
    "    n_cols = 6\n",
    "    n_rows = int(np.ceil(len(X_train.select_dtypes(include=\"number\")) / n_cols))\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*5, n_rows*4))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, col in enumerate(X_train.select_dtypes(include=\"number\")):\n",
    "        ax = axes[i]\n",
    "        try:\n",
    "            modelo = LinearRegression()\n",
    "            X_train_value = X_train[[col]]\n",
    "            modelo.fit(X_train_value, y_train)\n",
    "            previsao = modelo.predict(X_train_value)\n",
    "\n",
    "            r2 = round(r2_score(y_train, previsao), 2)\n",
    "            mse = round(mean_squared_error(y_train, previsao), 0)\n",
    "\n",
    "            sns.scatterplot(data=X_train_value, x=col, y=y_train, ax=ax, label=f\"r2: {r2}\\nmse: {mse}\")\n",
    "            sns.lineplot(x=X_train[col], y=previsao, color='red', ax=ax)\n",
    "\n",
    "            ax.set_title(col)\n",
    "            ax.legend()\n",
    "        except Exception as e:\n",
    "            ax.set_visible(False)\n",
    "            print(f\"Skipped {col} due to error: {e}\")\n",
    "\n",
    "    for j in range(i+1, len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ffae235-2396-4e19-803a-81574faced03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "show_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d12dbbf1-86d0-4d2d-ac81-ea6243669ee4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## CONSERTAR RESTANTE DO CODIGO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f14f15b7-7192-4382-8fda-1bc021503ad2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Realizando a remoção de alguns outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cf7c598-7eac-416e-b514-d5fea0157c13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train = train[train[\"SalePrice\"] <= 500000]\n",
    "train = train[train[\"GrLivArea\"] <= 4000]\n",
    "train = train[train[\"TotalBsmtSF\"] <= 3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "797ef535-4bc5-4b4b-8d02-0a8a4c5faec7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "show_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8eb2684c-0061-41a4-b86d-7bf995f9800b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Verificando Distribuição de preço de acordo com boxplots. Criando uma função que permita visualizar os dados de acordo com os valores únicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b8dcccc-90bd-4e3a-bf34-c6103908fef9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def tabela_de_frequencia(df, col, col_target):\n",
    "    \"\"\"\n",
    "    Gera um DataFrame com:\n",
    "    - Frequência absoluta\n",
    "    - Frequência relativa (%)\n",
    "    - Estatísticas de col_target (média, mediana, std, min, max, Q1, Q3)\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame de entrada\n",
    "        col (str): Nome da coluna categórica a ser analisada\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Tabela resumo com frequências e estatísticas de posição e dispersão\n",
    "    \"\"\"\n",
    "\n",
    "    frequencias = df[col].value_counts(dropna=False)\n",
    "    frequencias_rel = df[col].value_counts(normalize=True, dropna=False) * 100\n",
    "\n",
    "    # Estatísticas de SalePrice por categoria\n",
    "    estatisticas = df.groupby(col)[col_target].agg(\n",
    "        q25=lambda x: x.quantile(0.25),\n",
    "        media=\"mean\",\n",
    "        mediana=\"median\",\n",
    "        desvio_padrao=\"std\",\n",
    "        q75=lambda x: x.quantile(0.75),\n",
    "        maximo=\"max\"\n",
    "    )\n",
    "\n",
    "    tabela = pd.DataFrame(\n",
    "        {\n",
    "            col: frequencias.index,\n",
    "            \"Frequência Absoluta\": frequencias.values,\n",
    "            \"Frequência Relativa (%)\": frequencias_rel.values,\n",
    "        }\n",
    "    ).set_index(col)\n",
    "\n",
    "    tabela = tabela.join(estatisticas)\n",
    "    tabela = tabela.round(2)\n",
    "\n",
    "    return tabela.reset_index()\n",
    "\n",
    "\n",
    "def visualizacao_box_plot(df, col, col_target):\n",
    "    \"\"\"\n",
    "    Gera um boxplot para a coluna col comparando com SalePrice.\n",
    "\n",
    "    Parâmetros:\n",
    "    - df: DataFrame pandas contendo os dados\n",
    "    - col: string, nome da coluna categórica a ser usada no eixo X\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(data=df, x=col, y=col_target, hue=col, legend=False)\n",
    "    plt.title(f\"Boxplot de SalePrice por {col}\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ade709b0-c011-4263-a891-e532c9af9ae0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### A classifação da área Impacta no preço do empreendimento?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1de4c915-8154-4123-9c25-156216b17b9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "colunas = train.select_dtypes(include=\"object\").columns\n",
    "n_cols = 5 \n",
    "n_rows = int(np.ceil(len(colunas) / n_cols))\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*10, n_rows*9))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(colunas):\n",
    "    ax = axes[i]\n",
    "    try:\n",
    "        sns.boxplot(data=train, x=col, y=\"SalePrice\", hue=col, ax=ax, legend=False)\n",
    "        ax.set_title(col)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "    except Exception as e:\n",
    "        ax.set_visible(False)\n",
    "\n",
    "for j in range(i+1, len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a13f6710-08ab-47a0-bc99-624620cc5b38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tabela_de_frequencia(train, \"MSZoning\", \"SalePrice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ffb1bad-42ff-441c-86d6-e6c7da3cc897",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Principais pontos da Zona:\n",
    "1. O dataset é composto majoritariamente por partes residenciais de baixa densidade.\n",
    "2. O Conjunto de baixa densidade possui um número alto de dispersão, com o maior desvio padrão entre as séries, isso provavelmente se deve ao fato que tanto residências em locais de pouca habitação como regiões mais rurais e regiões mais ricas onde o número de casas é menor devido a extensão das casas pode explicar esse fato.\n",
    "3. Podemos fazer uma verificação do tamanho das casas em cada MSZoning para verificar se existe essa relação, dado que casas mais caras podem ser casas maiores, o que causaria o aumento do preço.\n",
    "\n",
    "Para verificar isso, podemos identificar a distribuição de tamanho de casas para casa tipo de zona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c718a867-cded-4a8f-9160-372c95dc0cd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "visualizacao_box_plot(train, \"MSZoning\", \"LotArea\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66e7e5bb-c416-4ce2-abf5-7628b76b87c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Como esperado, as residências em regiões de baixa densidade também contém os outliers em relação com tamanho residencial. Com relação a distribuição de residências com baixa residência, é estimado que 45% da área de Ames é relacionada com residências de unifamiliares, que geralmente são classificadas como baixa densidade residencial.\n",
    "[Referência: Zoneamento de Ames, Iowa](https://www.zoneomics.com/zoning-maps/iowa/ames?utm_source=chatgpt.com)\n",
    "\n",
    "Entretanto, considerando o exposto, podemos tentar entender o preço da residência de acordo com o tamanho de sua extensão, vamos verificar isso com um gráfico de correlação entre preço e tamanho da área e verificar como se distribuem de acordo com o Zoneamento"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5711032330399772,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Tratamento dos dados - EDA",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "GreenGarden",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
